{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75095c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "random_seed = 12738\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "804540fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_content</th>\n",
       "      <th>review_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Medio berreta, no justifica el gasto, ya se sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excelente !! superó mi expectativas. Lo único ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Es una buena relación calidad/precio. La cámar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Muy poca voluntad para ayudarme con cambiarlo,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nunca me respondieron por el manual de uso. En...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461870</th>\n",
       "      <td>Todavía no me lo entraron que paso?.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461871</th>\n",
       "      <td>Excelente muy bueno el producto.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461872</th>\n",
       "      <td>Muy delgado el armazón son muy frágiles, no du...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461873</th>\n",
       "      <td>La verdad un kit excelente, simple de instalar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461874</th>\n",
       "      <td>Producto que cumple su función, tiene una ilum...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>369500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           review_content  review_rate\n",
       "0       Medio berreta, no justifica el gasto, ya se sa...            0\n",
       "2       Excelente !! superó mi expectativas. Lo único ...            1\n",
       "3       Es una buena relación calidad/precio. La cámar...            1\n",
       "4       Muy poca voluntad para ayudarme con cambiarlo,...            0\n",
       "5       Nunca me respondieron por el manual de uso. En...            0\n",
       "...                                                   ...          ...\n",
       "461870               Todavía no me lo entraron que paso?.            0\n",
       "461871                   Excelente muy bueno el producto.            0\n",
       "461872  Muy delgado el armazón son muy frágiles, no du...            0\n",
       "461873  La verdad un kit excelente, simple de instalar...            1\n",
       "461874  Producto que cumple su función, tiene una ilum...            1\n",
       "\n",
       "[369500 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import Melisa2Dataset\n",
    "\n",
    "df_all = Melisa2Dataset().get_train_dataframe(usecols=['review_content','review_rate'])#.sample(n=10000,random_state=random_seed).reset_index(drop=True)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9f3259",
   "metadata": {},
   "source": [
    "# Clasificación de polaridad con un modelo Softmax\n",
    "\n",
    "En este caso vamos a representar a cada documento como una secuencia de word embeddings formados por dos features: la cantidad de veces que la palabra apareció en un documento de polaridad positiva y la cantidad de veces que apareció en uno de polaridad negativa. Luego, cada secuencia ingresa a un clasificador SoftMax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e48f92bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class SoftMaxClassifier(object):\n",
    "    \"\"\"\n",
    "    Implementación de un clasificador con word-by-category embeddings + CBOW + Softmax\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,tokenizer=None,vocab=None,max_features=None,ngram_range=(1,1)):\n",
    "        self.vec = CountVectorizer(tokenizer=tokenizer,vocabulary=vocab,\n",
    "                                   max_features=max_features,ngram_range=ngram_range,\n",
    "                                   lowercase=True)\n",
    "        self.clf = LogisticRegression()\n",
    "\n",
    "    def train(self,ds_train,y_train):\n",
    "        X = self.vec.fit_transform(ds_train)\n",
    "        y_train = y_train.astype(int)\n",
    "        y_one_hot = np.zeros((y_train.size,y_train.max()+1),dtype=float)\n",
    "        y_one_hot[np.arange(y_train.size),y_train] = 1.\n",
    "        self.W = X.minimum(1).T.dot(y_one_hot)\n",
    "        X_train = X.dot(self.W)\n",
    "        self.clf.fit(X_train,y_train)\n",
    "\n",
    "    def predict(self,ds_val):\n",
    "        X_val = self.vec.transform(ds_val).astype(float)\n",
    "        X_val = X_val.dot(self.W)\n",
    "        y_pred = self.clf.predict(X_val)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f695a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy obtenida con ngram_range=(1, 1), max_features=10000:\n",
      "Train accuracy: 74.94%\n",
      "Validation accuracy: 74.77%\n"
     ]
    }
   ],
   "source": [
    "from utils.evaluation import train_dev_validation\n",
    "import re\n",
    "\n",
    "ngram_range = (1,1)\n",
    "max_features = 10000\n",
    "token_pattern = re.compile(r'[\\w]+|[!¡¿\\?\\.,\\'\"]')\n",
    "tokenizer = lambda x: token_pattern.findall(x)\n",
    "model = SoftMaxClassifier(tokenizer=tokenizer,\n",
    "                          max_features=max_features,\n",
    "                          ngram_range=ngram_range)\n",
    "\n",
    "score = train_dev_validation(model,df_all,random_state=random_seed,metrics='accuracy',\n",
    "                     dev_size=.05,compute_train=True)\n",
    "\n",
    "print('Accuracy obtenida con ngram_range={}, max_features={}:'.format(ngram_range,max_features))\n",
    "try:\n",
    "    print('Train accuracy: {:.2f}%'.format(score['train_accuracy']*100))\n",
    "    print('Validation accuracy: {:.2f}%'.format(score['validation_accuracy']*100))\n",
    "except KeyError:\n",
    "    print('Accuracy: {:.2f}%'.format(score['accuracy']*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0022df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n"
     ]
    }
   ],
   "source": [
    "from utils.evaluation import k_fold_validation\n",
    "import re\n",
    "\n",
    "ngram_range = (1,2)\n",
    "max_features = 100000\n",
    "token_pattern = re.compile(r'[\\w]+|[!¡¿\\?\\.,\\'\"]')\n",
    "tokenizer = lambda x: token_pattern.findall(x)\n",
    "model = SoftMaxClassifier(tokenizer=tokenizer,\n",
    "                          max_features=max_features,\n",
    "                          ngram_range=ngram_range)\n",
    "\n",
    "score = k_fold_validation(model,df_all,5,random_state=random_seed,metrics='accuracy')\n",
    "\n",
    "print('Accuracy obtenida con ngram_range={}, max_features={}:'.format(ngram_range,max_features))\n",
    "print('Accuracy: {:.2f}%'.format(score['accuracy']*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc89606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluation import get_score\n",
    "import re\n",
    "\n",
    "df_test = Melisa2Dataset().get_train_dataframe(usecols=['review_content','review_rate'])#.sample(n=10000,random_state=random_seed).reset_index(drop=True)\n",
    "\n",
    "ngram_range = (1,3)\n",
    "max_features = 100000\n",
    "token_pattern = re.compile(r'[\\w]+|[!¡¿\\?.,\\'\"]')\n",
    "tokenizer = lambda x: token_pattern.findall(x)\n",
    "model = TfIdfBOWNaiveBayesClassifier(alpha=1.0,\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_features=max_features,\n",
    "                                ngram_range=ngram_range)\n",
    "\n",
    "model.train(df_all['review_content'],df_all['review_rate'].values)\n",
    "y_predict = model.predict(df_test['review_content'])\n",
    "score = get_score(df_test['review_rate'].values,y_predict,'accuracy')\n",
    "\n",
    "print('Accuracy obtenida con ngram_range={}, max_features={}:'.format(ngram_range,max_features))\n",
    "print('Accuracy: {:.2f}%'.format(score['accuracy']*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2801641f",
   "metadata": {},
   "source": [
    "# Resultados en validación (5-fold)\n",
    "\n",
    "```\n",
    "Accuracy obtenida con ngram_range=(1, 1), max_features=10000:\n",
    "Accuracy: 74.93%\n",
    "\n",
    "Accuracy obtenida con ngram_range=(1, 1), max_features=100000:\n",
    "Accuracy: 74.93%\n",
    "\n",
    "Accuracy obtenida con ngram_range=(1, 2), max_features=100000:\n",
    "Accuracy: 77.01%\n",
    "\n",
    "Accuracy obtenida con ngram_range=(1, 2), max_features=500000:\n",
    "Accuracy: 77.01%\n",
    "\n",
    "Accuracy obtenida con ngram_range=(1, 3), max_features=100000:\n",
    "Accuracy: 77.42%\n",
    "```\n",
    "\n",
    "# Resultados para test\n",
    "\n",
    "```\n",
    "Accuracy obtenida con ngram_range=(1, 3), max_features=100000:\n",
    "Accuracy: 77.43%\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
