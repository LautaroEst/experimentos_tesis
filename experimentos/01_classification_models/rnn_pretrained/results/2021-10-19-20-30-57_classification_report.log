


Descripción del experimento:
----------------------------

Modelo de clasificación con red neuronal recurrente vainilla
utilizando vectores de palabras preentrenados. El entrenamiento
se hace end-to-end.

Argumentos del entrenamiento utilizados:
- Cantidad de clases: 5
- Idioma: español
- Proporción utilizada para dev: 0.05
- Mostrar los datos cada 100 batches.

Argumentos del tokenizador:
- Patrón para pretokenizar: (\w+|[\.,!\(\)"\-:\?/%;¡\$'¿\\]|\d+)
- Frecuencia mínima: 5
- Cantidad máxima de tokens en el vocabulario: 10000
- Cantidad máxima de tokens por review: 128

Argumentos del modelo:
- Embeddings utilizados: word2vec
- Dimensión de las capas ocultas: 200
- Cantidad de capas ocultas (recurrentes): 1
- Probabilidad de dropout: 0.0
- Tamaño del batch: 128
- Tasa de aprendizaje: 0.0001
- Cantidad de epochs: 1
- Dispositivo de entrenamiento: cuda:1



Classification report (train):
------------------------------
    
              precision    recall  f1-score   support

           0       0.67      0.61      0.64     87782
           1       0.49      0.54      0.51     87875
           2       0.49      0.44      0.46     87921
           3       0.46      0.51      0.48     87694
           4       0.67      0.67      0.67     87977

    accuracy                           0.55    439249
   macro avg       0.56      0.55      0.55    439249
weighted avg       0.56      0.55      0.55    439249



Classification report (dev):
------------------------------
    
              precision    recall  f1-score   support

           0       0.68      0.60      0.64      4695
           1       0.49      0.53      0.51      4574
           2       0.48      0.43      0.46      4566
           3       0.47      0.52      0.49      4807
           4       0.67      0.66      0.67      4477

    accuracy                           0.55     23119
   macro avg       0.56      0.55      0.55     23119
weighted avg       0.56      0.55      0.55     23119


    