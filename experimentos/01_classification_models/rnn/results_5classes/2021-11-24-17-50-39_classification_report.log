


Descripción del experimento:
----------------------------

Modelo de clasificación con una red neuronal recurrente LSTM.

Argumentos del entrenamiento utilizados:
- Cantidad de clases: 5
- Idioma: es
- Cantidad máxima de palabras en el vocabulario: 60000
- Frecuencia mínima de cada palabra: 1
- Cantidad máxima de tokens por review: 512
- Dimensión de los embeddings: 300
- Red bidireccional: True
- Dimensión de las capas ocultas: 200
- Cantidad de capas ocultas (recurrentes): 2
- Probabilidad de dropout: 0.0
- Tamaño del batch: 256
- Tasa de aprendizaje: 0.0005
- Cantidad de epochs: 16
- Dispositivo de entrenamiento: cuda:1
- Mostrar los datos cada 100 batches.
- Proporción utilizada para dev: 0.05


Classification Report (Train):
------------------------------
    
              precision    recall  f1-score   support

           0       0.99      0.98      0.99     87782
           1       0.98      0.98      0.98     87875
           2       0.99      0.99      0.99     87921
           3       0.99      0.99      0.99     87694
           4       1.00      0.99      0.99     87977

    accuracy                           0.99    439249
   macro avg       0.99      0.99      0.99    439249
weighted avg       0.99      0.99      0.99    439249



Classification Report (Dev):
------------------------------
    
              precision    recall  f1-score   support

           0       0.66      0.61      0.63      4695
           1       0.51      0.53      0.52      4574
           2       0.53      0.55      0.54      4566
           3       0.57      0.58      0.57      4807
           4       0.75      0.71      0.73      4477

    accuracy                           0.60     23119
   macro avg       0.60      0.60      0.60     23119
weighted avg       0.60      0.60      0.60     23119


    