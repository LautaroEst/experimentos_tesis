


Descripción del experimento:
----------------------------

Modelo de clasificación con una red neuronal recurrente LSTM.

Argumentos del entrenamiento utilizados:
- Cantidad de clases: 5
- Idioma: es
- Cantidad máxima de palabras en el vocabulario: 60000
- Frecuencia mínima de cada palabra: 1
- Cantidad máxima de tokens por review: 512
- Dimensión de los embeddings: 300
- Red bidireccional: True
- Dimensión de las capas ocultas: 200
- Cantidad de capas ocultas (recurrentes): 1
- Probabilidad de dropout: 0.2
- Tamaño del batch: 256
- Tasa de aprendizaje: 0.0005
- Cantidad de epochs: 8
- Dispositivo de entrenamiento: cuda:1
- Mostrar los datos cada 100 batches.


Classification Report (Train):
------------------------------
    
              precision    recall  f1-score   support

           0      0.839     0.844     0.842     92477
           1      0.782     0.786     0.784     92449
           2      0.855     0.858     0.856     92487
           3      0.843     0.884     0.863     92501
           4      0.964     0.903     0.932     92454

    accuracy                          0.855    462368
   macro avg      0.857     0.855     0.855    462368
weighted avg      0.857     0.855     0.855    462368


MAE(%): 15.22


Classification Report (Test):
------------------------------
    
              precision    recall  f1-score   support

           0      0.673     0.678     0.675      5000
           1      0.537     0.596     0.565      5000
           2      0.537     0.550     0.543      5000
           3      0.528     0.561     0.544      5000
           4      0.789     0.629     0.700      5000

    accuracy                          0.603     25000
   macro avg      0.613     0.603     0.605     25000
weighted avg      0.613     0.603     0.605     25000


MAE(%): 15.22

    