


Descripción del experimento:
----------------------------

Modelo de clasificación con una red neuronal recurrente LSTM.

Argumentos del entrenamiento utilizados:
- Cantidad de clases: 2
- Idioma: es
- Cantidad máxima de palabras en el vocabulario: 60000
- Frecuencia mínima de cada palabra: 1
- Cantidad máxima de tokens por review: 512
- Dimensión de los embeddings: 300
- Red bidireccional: True
- Dimensión de las capas ocultas: 200
- Cantidad de capas ocultas (recurrentes): 1
- Probabilidad de dropout: 0.7
- Tamaño del batch: 256
- Tasa de aprendizaje: 0.0005
- Cantidad de epochs: 8
- Dispositivo de entrenamiento: cuda:1
- Mostrar los datos cada 100 batches.
- Proporción utilizada para dev: 0.05


Classification Report (Train):
------------------------------
    
              precision    recall  f1-score   support

           0      0.993     0.998     0.995    175672
           1      0.998     0.993     0.995    175714

    accuracy                          0.995    351386
   macro avg      0.995     0.995     0.995    351386
weighted avg      0.995     0.995     0.995    351386


MAE(%): 0.46


Classification Report (Dev):
------------------------------
    
              precision    recall  f1-score   support

           0      0.951     0.965     0.958      9254
           1      0.964     0.950     0.957      9241

    accuracy                          0.958     18495
   macro avg      0.958     0.957     0.957     18495
weighted avg      0.958     0.958     0.957     18495


MAE(%): 0.46

    