


Descripción del experimento:
----------------------------

Modelo de clasificación con un modelo de bolsa de palabras continuo.

Argumentos del entrenamiento utilizados:
- Cantidad de clases: 2
- Idioma: es
- Cantidad máxima de palabras en el vocabulario: 60000
- Frecuencia mínima de cada palabra: 1
- Cantidad máxima de tokens por review: 512
- Dimensión de los embeddings: 300
- Dimensión de las capas ocultas: 200
- Cantidad de capas ocultas: 4
- Probabilidad de dropout: 0.5
- Tamaño del batch: 256
- Tasa de aprendizaje: 0.0005
- Cantidad de epochs: 8
- Dispositivo de entrenamiento: cuda:1
- Mostrar los datos cada 100 batches.


Classification Report (Train):
------------------------------
    
              precision    recall  f1-score   support

           0      0.971     0.983     0.977    184926
           1      0.983     0.970     0.976    184955

    accuracy                          0.977    369881
   macro avg      0.977     0.977     0.977    369881
weighted avg      0.977     0.977     0.977    369881


MAE(%): 2.34


Classification Report (Test):
------------------------------
    
              precision    recall  f1-score   support

           0      0.899     0.945     0.921     10000
           1      0.942     0.894     0.917     10000

    accuracy                          0.919     20000
   macro avg      0.921     0.919     0.919     20000
weighted avg      0.921     0.919     0.919     20000


MAE(%): 2.34

    