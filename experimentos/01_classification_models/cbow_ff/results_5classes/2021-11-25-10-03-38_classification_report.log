


Descripción del experimento:
----------------------------

Modelo de clasificación con un modelo de bolsa de palabras continuo.

Argumentos del entrenamiento utilizados:
- Cantidad de clases: 5
- Idioma: es
- Cantidad máxima de palabras en el vocabulario: 60000
- Frecuencia mínima de cada palabra: 1
- Cantidad máxima de tokens por review: 512
- Dimensión de los embeddings: 300
- Dimensión de las capas ocultas: 200
- Cantidad de capas ocultas: 4
- Probabilidad de dropout: 0.5
- Tamaño del batch: 256
- Tasa de aprendizaje: 0.0005
- Cantidad de epochs: 8
- Dispositivo de entrenamiento: cuda:1
- Mostrar los datos cada 100 batches.


Classification Report (Train):
------------------------------
    
              precision    recall  f1-score   support

           0      0.704     0.731     0.717     92477
           1      0.640     0.533     0.582     92449
           2      0.600     0.654     0.626     92487
           3      0.637     0.637     0.637     92501
           4      0.792     0.823     0.807     92454

    accuracy                          0.676    462368
   macro avg      0.675     0.676     0.674    462368
weighted avg      0.675     0.676     0.674    462368


MAE(%): 36.83


Classification Report (Test):
------------------------------
    
              precision    recall  f1-score   support

           0      0.651     0.674     0.662      5000
           1      0.546     0.528     0.537      5000
           2      0.491     0.529     0.509      5000
           3      0.524     0.481     0.501      5000
           4      0.718     0.717     0.717      5000

    accuracy                          0.586     25000
   macro avg      0.586     0.586     0.585     25000
weighted avg      0.586     0.586     0.585     25000


MAE(%): 36.83

    