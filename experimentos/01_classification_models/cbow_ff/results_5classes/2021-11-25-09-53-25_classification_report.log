


Descripción del experimento:
----------------------------

Modelo de clasificación con un modelo de bolsa de palabras continuo.

Argumentos del entrenamiento utilizados:
- Cantidad de clases: 5
- Idioma: es
- Cantidad máxima de palabras en el vocabulario: 60000
- Frecuencia mínima de cada palabra: 1
- Cantidad máxima de tokens por review: 512
- Dimensión de los embeddings: 300
- Dimensión de las capas ocultas: 200
- Cantidad de capas ocultas: 4
- Probabilidad de dropout: 0.2
- Tamaño del batch: 256
- Tasa de aprendizaje: 0.0005
- Cantidad de epochs: 16
- Dispositivo de entrenamiento: cuda:1
- Mostrar los datos cada 100 batches.
- Proporción utilizada para dev: 0.05


Classification Report (Train):
------------------------------
    
              precision    recall  f1-score   support

           0      0.827     0.803     0.815     87782
           1      0.734     0.755     0.745     87875
           2      0.801     0.809     0.805     87921
           3      0.811     0.838     0.824     87694
           4      0.933     0.892     0.912     87977

    accuracy                          0.820    439249
   macro avg      0.821     0.820     0.820    439249
weighted avg      0.821     0.820     0.820    439249


MAE(%): 19.35


Classification Report (Dev):
------------------------------
    
              precision    recall  f1-score   support

           0      0.659     0.627     0.643      4695
           1      0.508     0.524     0.516      4574
           2      0.474     0.491     0.482      4566
           3      0.515     0.535     0.525      4807
           4      0.715     0.671     0.692      4477

    accuracy                          0.569     23119
   macro avg      0.574     0.570     0.572     23119
weighted avg      0.574     0.569     0.571     23119


MAE(%): 19.35

    