
Args:

model_name: xlm-roberta-sent
dataset: tass
nclasses: 3
split: test
devsize: 0.0
model_src: cardiffnlp/twitter-xlm-roberta-base-sentiment
dropout: 0.0
batch_size: 8
learning_rate: 1e-05
num_epochs: 1
device: cuda:1

Results:

Train Accuracy: 83.80%
Test/Dev Accuracy: 84.69%
Train f1-score: 60.54%
Test/Dev f1-score: 57.93%
Train MAE: 20.71%
Test/Dev MAE: 26.96%
    