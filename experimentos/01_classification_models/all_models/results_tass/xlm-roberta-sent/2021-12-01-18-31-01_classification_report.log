
Args:

model_name: xlm-roberta-sent
dataset: tass
nclasses: 5
split: test
devsize: 0.0
model_src: cardiffnlp/twitter-xlm-roberta-base-sentiment
dropout: 0.0
batch_size: 8
learning_rate: 1e-05
num_epochs: 1
device: cuda:1

Results:

Train Accuracy: 59.27%
Test/Dev Accuracy: 55.58%
Train f1-score: 49.86%
Test/Dev f1-score: 39.15%
Train MAE: 50.35%
Test/Dev MAE: 68.85%
    