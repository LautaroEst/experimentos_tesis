


Descripción del experimento:
----------------------------

Modelo de clasificación con un modelo Bolsa de Features (catgorías) + 2LayerNet.

Argumentos del entrenamiento utilizados:
- Cantidad de clases: 2
- Idioma: es
- Rango de los n-gramas: [1, 3]
- Cantidad máxima de features en el vocabulario: 100000
- Dimensión de la capa oculta: 400
- Tamaño del batch: 256
- Tasa de aprendizaje: 1e-05
- Cantidad de epochs: 8
- Weight Decay: 0.0
- Dispositivo de entrenamiento: cuda:1
- Mostrar los datos cada 100 batches.
- Proporción utilizada para dev: 0.05


Classification Report (Train):
------------------------------

              precision    recall  f1-score   support

           0      0.766     0.846     0.804    175672
           1      0.828     0.742     0.783    175714

    accuracy                          0.794    351386
   macro avg      0.797     0.794     0.793    351386
weighted avg      0.797     0.794     0.793    351386

    
MAE(%): 20.62


Classification Report (Dev):
------------------------------
    
              precision    recall  f1-score   support

           0      0.769     0.849     0.807      9254
           1      0.831     0.745     0.786      9241

    accuracy                          0.797     18495
   macro avg      0.800     0.797     0.796     18495
weighted avg      0.800     0.797     0.796     18495


MAE(%): 20.62

    