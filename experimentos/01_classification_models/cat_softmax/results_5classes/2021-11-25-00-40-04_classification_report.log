


Descripción del experimento:
----------------------------

Modelo de clasificación con un modelo Bolsa de Features (catgorías) + 2LayerNet.

Argumentos del entrenamiento utilizados:
- Cantidad de clases: 5
- Idioma: es
- Rango de los n-gramas: [1, 2]
- Cantidad máxima de features en el vocabulario: 100000
- Dimensión de la capa oculta: 10
- Tamaño del batch: 512
- Tasa de aprendizaje: 0.0005
- Cantidad de epochs: 16
- Weight Decay: 0.0
- Dispositivo de entrenamiento: cuda:1
- Mostrar los datos cada 100 batches.
- Proporción utilizada para dev: 0.05


Classification Report (Train):
------------------------------
    
              precision    recall  f1-score   support

           0       0.46      0.47      0.47     87782
           1       0.39      0.55      0.46     87875
           2       0.40      0.18      0.25     87921
           3       0.45      0.21      0.28     87694
           4       0.47      0.77      0.58     87977

    accuracy                           0.44    439249
   macro avg       0.43      0.44      0.41    439249
weighted avg       0.43      0.44      0.41    439249



Classification Report (Dev):
------------------------------
    
              precision    recall  f1-score   support

           0       0.47      0.47      0.47      4695
           1       0.38      0.54      0.44      4574
           2       0.41      0.18      0.25      4566
           3       0.46      0.20      0.28      4807
           4       0.45      0.76      0.57      4477

    accuracy                           0.43     23119
   macro avg       0.43      0.43      0.40     23119
weighted avg       0.43      0.43      0.40     23119


    