{
    "dataset": "amazon",
    "model": {
        "name": "cbow",
        "embeddings": "fasttext300",
        "hidden_sizes": [
            300,
            200,
            100,
            50
        ],
        "dropout": 0.0
    },
    "tokenizer": {
        "name": "word_tokenizer",
        "max_sent_len": 512,
        "max_tokens": 60000,
        "freq_cutoff": 1,
        "pad_token": "[PAD]",
        "unk_token": "[UNK]"
    },
    "train_kwargs": {
        "max_epochs": 50,
        "train_batch_size": 32,
        "dev_batch_size": 64,
        "learning_rate": 0.0001,
        "patience": 10,
        "train_eval_every": 100,
        "dev_eval_every": 1000,
        "device": "cuda:1"
    }
}