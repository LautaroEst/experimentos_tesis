{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea51ac6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils as ut\n",
    "\n",
    "DATA_PATH = '../../datav2/esp/'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4c7c2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado para 5 clases (muy malo=0, malo=2, medio=3, bueno=4 muy bueno=1)\n",
      "Num samples per category:\n",
      "1    92477\n",
      "2    92449\n",
      "3    92487\n",
      "4    92501\n",
      "5    92454\n",
      "Name: review_rate, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_content</th>\n",
       "      <th>review_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Esta de muy baja calidad, no fue lo esperado.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reconozco que fue muy económico, pero su durab...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Muy bien muy bien muy bien muy bien muy bien m...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No me fue útil para mí. Diseño muy bueno.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No fue lo estipulado. Solo eso voy aclarar.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      review_content  review_rate\n",
       "0      Esta de muy baja calidad, no fue lo esperado.            2\n",
       "1  Reconozco que fue muy económico, pero su durab...            2\n",
       "2  Muy bien muy bien muy bien muy bien muy bien m...            5\n",
       "3          No me fue útil para mí. Diseño muy bueno.            2\n",
       "4        No fue lo estipulado. Solo eso voy aclarar.            1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ut.load_data(DATA_PATH,'train',nclasses=5).loc[:,['review_content','review_rate']]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['country', 'category', 'review_content', 'review_title', 'review_rate']\n",
      "['MLM', 'Salud, ropa y cuidado personal / Saúde, roupas e cuidado pessoal', 'Esta de muy baja calidad, no fue lo esperado.', 'No fue lo esperado ', '2']\n",
      "['MLA', 'Salud, ropa y cuidado personal / Saúde, roupas e cuidado pessoal', 'Reconozco que fue muy económico, pero su durabilidad fue muy corta.', 'Malo', '2']\n",
      "['MLV', 'Tecnología y electrónica / Tecnologia e electronica', 'Muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bien muy bi.', 'Excelente', '5']\n",
      "['MLA', 'Salud, ropa y cuidado personal / Saúde, roupas e cuidado pessoal', 'No me fue útil para mí. Diseño muy bueno.', 'Malo', '2']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open(DATA_PATH + 'train.csv', 'r') as f:\n",
    "    csv_reader = csv.reader(f,delimiter=',',lineterminator='\\n')\n",
    "    fieldnames = next(csv_reader)\n",
    "    for i, line in enumerate(csv_reader):\n",
    "        if i >= 5:\n",
    "            break\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1038732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tokenizers import RegexTokenizer, NLTKWordTokenizer, NLTKTweetTokenizer\n",
    "\n",
    "def normalize_dataset(df):\n",
    "    # Pasamos a minúscula todo\n",
    "    df['review_content'] = df['review_content'].str.lower()\n",
    "    # Sacamos todos los acentos\n",
    "    for rep, rep_with in [('[óòÓöøôõ]','o'), ('[áàÁäåâãÄ]','a'), ('[íìÍïîÏ]','i'), \n",
    "                          ('[éèÉëêÈ]','e'), ('[úüÚùûÜ]','u'), ('[ç¢Ç]','c'), \n",
    "                          ('[ý¥]','y'),('š','s'),('ß','b'),('\\x08','')]:\n",
    "        df['review_content']  = df['review_content'].str.replace(rep,rep_with,regex=True)\n",
    "    return df\n",
    "\n",
    "def train_tokenizers(df_train,max_words,freq_cutoff,ngram_range,unk_token):\n",
    "\n",
    "    tokenizers = {\n",
    "        'regex': RegexTokenizer(r'(\\w+|[\\.,!\\(\\)\"\\-:\\?/%;¡\\$\\'¿\\\\]|\\d+)',\n",
    "                                max_words,freq_cutoff,ngram_range,unk_token),\n",
    "        'nltk': NLTKWordTokenizer('spanish',max_words,freq_cutoff,ngram_range,unk_token),\n",
    "        'tweet': NLTKTweetTokenizer(max_words,freq_cutoff,ngram_range,unk_token)\n",
    "    }\n",
    "\n",
    "\n",
    "    for name, tknzr in tokenizers.items():\n",
    "        print('{} tokenizer:'.format(name))\n",
    "        tknzr.train(df_train['review_content'])\n",
    "        print()\n",
    "        \n",
    "    return tokenizers\n",
    "        \n",
    "\n",
    "df = normalize_dataset(df)\n",
    "df_train, df_dev = ut.train_dev_split(df,dev_size=0.1,random_state=2376482)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5ccdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regex tokenizer:\n",
      "Vocab size: 4218\n",
      "\n",
      "nltk tokenizer:\n",
      "Vocab size: 4217\n",
      "\n",
      "tweet tokenizer:\n",
      "Vocab size: 4216\n",
      "\n",
      "Max words: 10000, cutoff frequency: 1, reweight: none\n",
      "Accuracy: 51.84%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.classifiers import NaiveBayesClassifier\n",
    "import pickle\n",
    "\n",
    "\n",
    "max_words = [10000]\n",
    "freq_cutoff = [1]\n",
    "ngram_range = (1,2)\n",
    "unk_token = None\n",
    "reweight = ['none','tfidf','ppmi']\n",
    "\n",
    "results = {}\n",
    "\n",
    "\n",
    "for mw in max_words:\n",
    "    for fc in freq_cutoff:\n",
    "        tokenizers = train_tokenizers(df_train.iloc[:100],mw,fc,ngram_range,unk_token)\n",
    "        for name,tknzr in tokenizers.items():\n",
    "            for rw in reweight:\n",
    "                # Fit:\n",
    "                clf = NaiveBayesClassifier(alpha=1.0,num_features=mw,reweight=rw)\n",
    "                ids_train = tknzr.sentences_to_ids(df_train.loc[:,'review_content'])\n",
    "                labels_train = df_train.loc[:,'review_rate'].values\n",
    "                clf.fit(ids_train,labels_train)\n",
    "                # Predict:\n",
    "                ids_dev = tknzr.sentences_to_ids(df_dev.loc[:,'review_content'])\n",
    "                y = df_dev.loc[:,'review_rate'].values\n",
    "                y_pred = clf.predict(ids_dev)\n",
    "                print('Max words: {}, cutoff frequency: {}, reweight: {}'.format(mw,fc,rw))\n",
    "                print('Accuracy: {:.2f}%'.format(sum(y_pred == y) * 100 / len(y_pred)))\n",
    "                print()\n",
    "\n",
    "                results[name] = {'max_words': mw, 'frequency_cutoff':fc, 'reweight':rw, \n",
    "                                 'ngram_range': ngram_range, 'unk_token': unk_token}\n",
    "        pickle.dump(results,'./nb_classification_5_classes_{}_{}.pkl'.format(mw,fc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46ffe78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(416131, 46237)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.size, y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "542be0c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f45937856810>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d31ac5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.85      0.88    184750\n",
      "         1.0       0.86      0.92      0.89    184750\n",
      "\n",
      "    accuracy                           0.88    369500\n",
      "   macro avg       0.89      0.88      0.88    369500\n",
      "weighted avg       0.89      0.88      0.88    369500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X,y)\n",
    "y_pred = clf.predict(X)\n",
    "print(classification_report(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54365fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.81      0.85    184750\n",
      "         1.0       0.83      0.91      0.87    184750\n",
      "\n",
      "    accuracy                           0.86    369500\n",
      "   macro avg       0.87      0.86      0.86    369500\n",
      "weighted avg       0.87      0.86      0.86    369500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_tfidf,y)\n",
    "y_pred = clf.predict(X_tfidf)\n",
    "print(classification_report(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3346d1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.85      0.87    184750\n",
      "         1.0       0.86      0.90      0.88    184750\n",
      "\n",
      "    accuracy                           0.88    369500\n",
      "   macro avg       0.88      0.88      0.88    369500\n",
      "weighted avg       0.88      0.88      0.88    369500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_ppmi,y)\n",
    "y_pred = clf.predict(X_ppmi)\n",
    "print(classification_report(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6 0.  0.2 0.2 0.8 0.4 0.4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.6, 0. , 0.2, 0.2, 0.8, 0.4, 0.4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "X = csr_matrix(np.array([[1,0,0,0,3,0,4],\n",
    "                         [0,0,1,0,1,1,0],\n",
    "                         [1,0,0,1,1,0,4],\n",
    "                         [2,0,0,0,3,2,0],\n",
    "                         [0,0,0,0,0,0,0]],dtype=float),shape=(5,7))\n",
    "\n",
    "df = np.asarray(X.astype(bool,copy=True).sum(axis=0)).squeeze() / X.shape[0]\n",
    "print(df)\n",
    "\n",
    "np.bincount(X.indices, minlength=X.shape[1])/ X.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
